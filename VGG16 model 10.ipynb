{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17adba5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VGG16\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizers\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load the 'horses_or_humans' dataset\u001b[39;00m\n\u001b[0;32m     10\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorses_or_humans\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m], as_supervised\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the 'horses_or_humans' dataset\n",
    "train_data, test_data = tfds.load('horses_or_humans', split=['train', 'test'], as_supervised=True)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "def preprocess_img(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "train_data = train_data.map(preprocess_img)\n",
    "test_data = test_data.map(preprocess_img)\n",
    "\n",
    "# Convert datasets to numpy arrays\n",
    "train_images = np.array([image.numpy() for image, _ in train_data])\n",
    "train_labels = np.array([label.numpy() for _, label in train_data])\n",
    "test_images = np.array([image.numpy() for image, _ in test_data])\n",
    "test_labels = np.array([label.numpy() for _, label in test_data])\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create the model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Create a new model on top of the pre-trained model\n",
    "model = models.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "    steps_per_epoch=len(train_images) // batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    validation_steps=len(test_images) // batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_score = model.evaluate(test_images, test_labels, batch_size=batch_size)\n",
    "print(f'Test loss: {test_score[0]}, Test accuracy: {test_score[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b4a75b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831ms/step\n",
      "Predicted Output: [[6.116732e-37]]\n",
      "Actual Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Select a sample from the dataset for prediction\n",
    "sample_image, sample_label = next(iter(test_data))\n",
    "sample_image = sample_image.numpy().reshape((1, 224, 224, 3))\n",
    "\n",
    "# Predict the output\n",
    "prediction = model.predict(sample_image)\n",
    "\n",
    "print(\"Predicted Output:\", prediction)\n",
    "print(\"Actual Label:\", sample_label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c01becd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-datasets\n",
      "  Obtaining dependency information for tensorflow-datasets from https://files.pythonhosted.org/packages/fe/18/4865973f5469cfe33bbe1cfc2f1918335eb44f4cc3d316c1bce22c1af2bc/tensorflow_datasets-4.9.4-py3-none-any.whl.metadata\n",
      "  Using cached tensorflow_datasets-4.9.4-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (8.0.4)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Collecting etils[enp,epath,etree]>=0.9.0 (from tensorflow-datasets)\n",
      "  Obtaining dependency information for etils[enp,epath,etree]>=0.9.0 from https://files.pythonhosted.org/packages/d0/3c/784b5f94bcad62a4167f2347fe1095b627433c22a54aecc4504237494b81/etils-1.8.0-py3-none-any.whl.metadata\n",
      "  Using cached etils-1.8.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.24.3)\n",
      "Collecting promise (from tensorflow-datasets)\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (3.20.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.31.0)\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets)\n",
      "  Obtaining dependency information for tensorflow-metadata from https://files.pythonhosted.org/packages/41/23/3705c7139886c079ef4c0e3be56a5a1fb90e9ee413a4b7caaee0ee0ea6fe/tensorflow_metadata-1.14.0-py3-none-any.whl.metadata\n",
      "  Using cached tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: termcolor in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.4.0)\n",
      "Requirement already satisfied: toml in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (4.65.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.14.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (2023.4.0)\n",
      "Collecting importlib_resources (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets)\n",
      "  Obtaining dependency information for importlib_resources from https://files.pythonhosted.org/packages/75/06/4df55e1b7b112d183f65db9503bff189e97179b256e1ea450a3c365241e0/importlib_resources-6.4.0-py3-none-any.whl.metadata\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (4.7.1)\n",
      "Requirement already satisfied: zipp in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from click->tensorflow-datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\navyasanju\\anaconda3\\lib\\site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Collecting absl-py (from tensorflow-datasets)\n",
      "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/dd/87/de5c32fa1b1c6c3305d576e299801d8655c175ca9557019906247b994331/absl_py-1.4.0-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow-datasets)\n",
      "  Obtaining dependency information for googleapis-common-protos<2,>=1.52.0 from https://files.pythonhosted.org/packages/dc/a6/12a0c976140511d8bc8a16ad15793b2aef29ac927baa0786ccb7ddbb6e1c/googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Using cached tensorflow_datasets-4.9.4-py3-none-any.whl (5.1 MB)\n",
      "Using cached tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached etils-1.8.0-py3-none-any.whl (156 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: promise, importlib_resources, googleapis-common-protos, etils, absl-py, tensorflow-metadata, tensorflow-datasets\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 2.1.0\n",
      "    Uninstalling absl-py-2.1.0:\n",
      "      Successfully uninstalled absl-py-2.1.0\n",
      "Successfully installed absl-py-1.4.0 etils-1.8.0 googleapis-common-protos-1.63.0 importlib_resources-6.4.0 promise-2.3 tensorflow-datasets-4.9.4 tensorflow-metadata-1.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62741c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
